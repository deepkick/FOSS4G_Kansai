{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is convolution ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src = \"./fig/cnn1.png\" width=250 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is an example of an image with  32 $*$ 32 pixels (length and width) 3 spectral bands (3 channels), 5 $*$ 5 kernel_size size [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below figure shows,how exactly it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./fig/cnn2.png\" width = 350 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each filter is independantly convolved with image and end up with user defined number of features. In the following figure has 6 features representation derived  from 6 filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./fig/cnn3.png\" width = 350 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where, CNN is collection of defined number of convolutional layers (blocks), convolutional (featues) result from one layer will be passed to the next layer as input as shown figure below; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./fig/cnn4.png\" width=300 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us go to more details by making our own simple CNN using Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "x_train,y_train = np.load('./dataset/isprs_vaihingen/train/patches/image.npy'),np.load('./dataset/isprs_vaihingen/train/patches/label.npy')\n",
    "x_test,y_test = np.load('./dataset/isprs_vaihingen/val/patches/image.npy'),np.load('./dataset/isprs_vaihingen/val/patches/label.npy')\n",
    "channel = x_train.shape[-1]\n",
    "num_classes = 5\n",
    "img_rows, img_cols = 256, 256\n",
    "input_shape = (img_rows, img_cols, channel)\n",
    "y_tra = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_tes = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense,Input,Activation,Conv2D, MaxPooling2D,UpSampling2D, Dropout,Conv2DTranspose, concatenate, Flatten,BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the **filters**, **kernel size**, **padding**,**strides**, **pooling** and number of **parameters** generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 10, kernel_size = (5,5), strides =1,padding = 'valid', \n",
    "                 input_shape=input_shape, activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is padding**  ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padding** is to add extra pixels to  outside the image to retain the original shape of the image after convolution [2]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./fig/no_padding_no_strides.gif\" width = 250>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./fig/arbitrary_padding_no_strides.gif\" width = 250>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 10, kernel_size = (5,5), strides = 1, padding = 'same', \n",
    "                 input_shape=input_shape, activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strides** is the unit of pixels which used to convolve  the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./fig/no_padding_strides.gif\" width = 250>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./fig/padding_strides.gif\" width = 250>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 10, kernel_size = (5,5), strides = 2, padding = 'same', \n",
    "                 input_shape=input_shape, activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pooling layer** downsamples the volume spatially, independently in each of the input feature. This function use to reduce the spatial size and hence reduce the number of paramters and computation. Eg: maxpool, averagepool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./fig/pooling.png\" width = 350 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 10, kernel_size = (5,5), strides = 1, padding = 'same', \n",
    "                 input_shape=input_shape, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building Encoder-decoder CNN network in Keras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is CNN network consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer.Several famous Encoder-decoder is available such as Segnet, U-net, Deconv-net etc,."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define our own simple Encoder-decoder network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all define the encoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((input_shape))\n",
    "conv1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool1)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.int_shape(pool2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the decoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool2)\n",
    "up1 = UpSampling2D(size=(2, 2),interpolation='nearest')(conv3)\n",
    "conv4 = Conv2D(16, (3, 3), activation='relu', padding='same')(up1)\n",
    "up2 = UpSampling2D(size=(2, 2),interpolation='nearest')(conv4)\n",
    "conv5 = Conv2D(num_classes, (1, 1), activation='softmax')(up2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.int_shape(conv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[inputs], outputs=[conv5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE= 32\n",
    "EPOCHS = 2\n",
    "#SGD = keras.optimizers.SGD(lr=0.01)\n",
    "SGD = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "catergorical = keras.losses.categorical_crossentropy\n",
    "accuracy = ['accuracy']\n",
    "model.compile(loss = catergorical, optimizer = SGD,\n",
    "              metrics = accuracy)\n",
    "\n",
    "history1 = model.fit(x_train, y_tra,\n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data = (x_test, y_tes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred,y_pred = np.load('./dataset/isprs_vaihingen/test/patches/image.npy'),np.load('./dataset/isprs_vaihingen/test/patches/label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict_prob = model.predict(x_pred)\n",
    "Predict_prob.shape\n",
    "Predict_class = np.argmax(Predict_prob,axis=-1)\n",
    "Predict_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib  notebook\n",
    "import matplotlib.pyplot as  plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121)\n",
    "ax.imshow(Predict_class[4], interpolation='none')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Predict')\n",
    "fig.show()\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.imshow(y_pred[4], interpolation='none')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Label')\n",
    "\n",
    "fig.suptitle('Scene: top_mosaic_09cm_area1')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**U-net; a deep Convolutional Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-net is an end-to-end network with U-shape. U-net consists of a contracting path (left-side) and an expansive path (right side). U-net has special architecture which concatenate lost features in the downsampling process with the appropriate features in the upsampling process. This particular aspect makes U-net as an elegant deep learning network[3]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./fig/unet.png\" width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((input_shape))\n",
    "# Encoder\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = BatchNormalization()(conv4)\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "# Decoder\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "conv6 = BatchNormalization()(conv6)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = BatchNormalization()(conv7)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "conv8 = BatchNormalization()(conv8)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "conv9 = BatchNormalization()(conv9)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "conv10 = Conv2D(num_classes, (1, 1), activation='softmax')(conv9)\n",
    "model = Model(inputs=[inputs], outputs=[conv10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE= 24\n",
    "EPOCHS = 1\n",
    "#SGD = keras.optimizers.SGD(lr=0.01)\n",
    "SGD = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "catergorical = keras.losses.categorical_crossentropy\n",
    "accuracy = ['accuracy']\n",
    "model.compile(loss = catergorical, optimizer = SGD,\n",
    "              metrics = accuracy)\n",
    "\n",
    "history1 = model.fit(x_train, y_tra,\n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data = (x_test, y_tes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "model_json = model.to_json()\n",
    "with open(\"./learned_weights/demo_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./learned_weights/demo_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict_prob = model.predict(x_pred)\n",
    "Predict_prob.shape\n",
    "Predict_class = np.argmax(Predict_prob,axis=-1)\n",
    "Predict_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121)\n",
    "ax.imshow(Predict_class[1], interpolation='none')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Predict')\n",
    "fig.show()\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.imshow(y_pred[1], interpolation='none')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Label')\n",
    "\n",
    "fig.suptitle('Scene: top_mosaic_09cm_area1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import h5py\n",
    "json_file = open('./learned_weights/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./learned_weights/model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict_prob = loaded_model.predict(x_pred)\n",
    "Predict_prob.shape\n",
    "Predict_class = np.argmax(Predict_prob,axis=-1)\n",
    "Predict_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121)\n",
    "ax.imshow(Predict_class[1], interpolation='none')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Predict')\n",
    "fig.show()\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.imshow(y_pred[1], interpolation='none')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Label')\n",
    "\n",
    "fig.suptitle('Scene: top_mosaic_09cm_area1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Harsh Pokharna, The best explanation of Convolutional Neural Networks on the Internet\n",
    "2. Vincent Dumoulin, Francesco Visin - A guide to convolution arithmetic for deep learning (BibTeX)\n",
    "3. Olaf Ronneberger, Philipp Fischer, Thomas Brox, U-Net: Convolutional Networks for Biomedical Image Segmentation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
