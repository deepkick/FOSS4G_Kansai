{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"},"colab":{"name":"MLP_keras.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"lGWPpUWhbALI","colab_type":"text"},"source":["##  Multi Layer Perceptron practice  for satellite images"]},{"cell_type":"markdown","metadata":{"id":"cEQj89W_bALJ","colab_type":"text"},"source":["It requires some codes, we are going to step over it slowly so that you will know how to create your own models in the future."]},{"cell_type":"markdown","metadata":{"id":"tYWoX_oIbALK","colab_type":"text"},"source":["The steps you are going to cover in this tutorial are as follows:\n","- Load libraries\n","- Load Data\n","- Define Model\n","- Compile Model\n","- Fit Model\n","- Evaluate Model"]},{"cell_type":"markdown","metadata":{"id":"0Zmm5Xe9bALL","colab_type":"text"},"source":["**Load necessary libraries**"]},{"cell_type":"markdown","metadata":{"id":"_a_j9JbzfA-X","colab_type":"text"},"source":["Mount google drive"]},{"cell_type":"code","metadata":{"id":"2bfTqzy1e7xJ","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vuJtJrNIe97p","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/content/drive/My Drive/FOSS4G_Kansai/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K2AnbztmeWPi","colab_type":"code","colab":{}},"source":["# ignore annoying warnings\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T3gDrAhsbALP","colab_type":"text"},"source":["We use Keras for this practice"]},{"cell_type":"code","metadata":{"id":"RWlBRj12bALP","colab_type":"code","colab":{}},"source":["import numpy as np\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Activation, Dense\n","model = Sequential()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Xgx6dtMbALS","colab_type":"text"},"source":["**Load the prepared data**"]},{"cell_type":"code","metadata":{"id":"0nQvKGTpbALS","colab_type":"code","colab":{}},"source":["x_train,y_train = np.load('./dataset/isprs_vaihingen/train/patches/image.npy'),np.load('./dataset/isprs_vaihingen/train/patches/label.npy')\n","x_test,y_test = np.load('./dataset/isprs_vaihingen/val/patches/image.npy'),np.load('./dataset/isprs_vaihingen/val/patches/label.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f5DYhozgbALU","colab_type":"code","colab":{}},"source":["print (x_train.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"71lxe_NHbALW","colab_type":"code","colab":{}},"source":["from keras import backend as K\n","print (K.image_data_format())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p5eaMucBbALY","colab_type":"code","colab":{}},"source":["print (int(y_train.max()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SdyrRUSSbALa","colab_type":"code","colab":{}},"source":["num_classes = 5\n","channel = x_train.shape[-1]\n","print (channel)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"USxkwNJNbALc","colab_type":"text"},"source":["Reshape the image patches to 1D vector for pixelwise perceptron learning"]},{"cell_type":"code","metadata":{"id":"d_k8IbxCbALd","colab_type":"code","colab":{}},"source":["x_train = x_train.reshape(x_train.shape[0]*x_train.shape[1]*x_train.shape[2],x_train.shape[3])\n","x_test = x_test.reshape(x_test.shape[0]*x_test.shape[1]*x_test.shape[2],x_test.shape[3])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZzWTDLGxbALf","colab_type":"code","colab":{}},"source":["print (x_train.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fyfhd-SkbALg","colab_type":"code","colab":{}},"source":["y_train = y_train.reshape(y_train.shape[0]*y_train.shape[1]*y_train.shape[2])\n","y_test = y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"opRPrOWKbALi","colab_type":"code","colab":{}},"source":["print (y_train.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jLIotuRHbALk","colab_type":"text"},"source":["**One-hot encoding** it is convinient to transfer categorical features to numerical  variables "]},{"cell_type":"markdown","metadata":{"id":"OTvhs-RYbALk","colab_type":"text"},"source":["Plot one sample using matplotlib"]},{"cell_type":"code","metadata":{"id":"qh-eEg7-bALl","colab_type":"code","colab":{}},"source":["y_tra = keras.utils.to_categorical(y_train, num_classes)\n","y_tes = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ThvJuC2kbALn","colab_type":"code","colab":{}},"source":["print(y_tra.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNVnBPojbALo","colab_type":"code","colab":{}},"source":["print(y_tra[0,])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"41VLOZ1WbALq","colab_type":"text"},"source":["**Define a model**"]},{"cell_type":"code","metadata":{"id":"DxfxCpkobALr","colab_type":"code","colab":{}},"source":["model = Sequential()\n","model.add(Dense(16, input_dim=(3), activation='relu'))\n","model.add(Dense(8, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k3Opp3rTbALs","colab_type":"text"},"source":["You already aware about Dense layers which is a fully connected layer. Now let us see what is **Activation functions** ?"]},{"cell_type":"markdown","metadata":{"id":"A_NfudAhbALt","colab_type":"text"},"source":["**Activation functions** are an extremely important feature of the artificial neural networks. They basically decide whether a neuron should be activated or not. Whether the information that the neuron is receiving is relevant for the given information or should it be ignored"]},{"cell_type":"markdown","metadata":{"id":"9HPvEE_lbALt","colab_type":"text"},"source":["**ReLU**"]},{"cell_type":"markdown","metadata":{"id":"1oznym_tbALu","colab_type":"text"},"source":["<center> $ A(x) = max(0,x) $ <center>"]},{"cell_type":"code","metadata":{"id":"h3wtCfBicI-j","colab_type":"code","colab":{}},"source":["from IPython.display import Image\n","Image('fig/ReLU.jpeg', width=500, height=300)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wt8Mfty-bALv","colab_type":"text"},"source":["**Sigmoid**"]},{"cell_type":"markdown","metadata":{"id":"MAtHT7jDbALw","colab_type":"text"},"source":["\\begin{equation*}\n","A(x) = \\frac{1}{(1-e^{-x})}\n","\\end{equation*}"]},{"cell_type":"code","metadata":{"id":"urt-WnUgcOWM","colab_type":"code","colab":{}},"source":["Image('fig/Sigmoid.png')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZYZU4qwQbALy","colab_type":"text"},"source":["**Compile Model**"]},{"cell_type":"markdown","metadata":{"id":"2xVijso4bALz","colab_type":"text"},"source":["Once we  define the model,  we  have to compile it. There are a few choices to be mentioned while we train the model "]},{"cell_type":"markdown","metadata":{"id":"C2ma-BeMbALz","colab_type":"text"},"source":["- Optimizer: specific algorithm to update weights while we train the model commonly used Optimizer  is **Stochastic Gradient Descent (SGD).**\n","- Loss function: Used to optimizer to navigate the space wights and the optimization is defined as a process of loss minimization (Some common choices of loss functions are **Binary cross-entropy**, **Categorical cross-entropy (Softmax cross entroy)**  and **Mean Squared Error (MSE)**)\n","- Evaluation of the model (Common choices are **accuracy**, **precision** and **recall**)"]},{"cell_type":"code","metadata":{"id":"78F4DqPsceiD","colab_type":"code","colab":{}},"source":["Image('fig/backpropog.png', width=850,height=350)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6WdfOVqc0N_","colab_type":"code","colab":{}},"source":["Image('fig/Metrics.png', width=350,height=200)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZW4ECFQbAL2","colab_type":"code","colab":{}},"source":["SGD = keras.optimizers.SGD(lr=0.01)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VuULVNNqbAL4","colab_type":"code","colab":{}},"source":["catergorical = keras.losses.categorical_crossentropy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YD2mQK-TbAL8","colab_type":"code","colab":{}},"source":["accuracy = ['accuracy']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TugN0pWPbAL-","colab_type":"code","colab":{}},"source":["model.compile(loss = catergorical, optimizer = SGD,\n","              metrics = accuracy)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iW4dPvWsbAMA","colab_type":"text"},"source":["**Fit Model**"]},{"cell_type":"markdown","metadata":{"id":"9EK4M6zcbAMA","colab_type":"text"},"source":["Once the model is compiled, it can be then trained with 'fit()' function in Keras, which specifies few paramters such as epochs, batch_size"]},{"cell_type":"code","metadata":{"id":"PDKq4Cm7bAMB","colab_type":"code","colab":{}},"source":["BATCH_SIZE= 30000\n","EPOCHS = 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NdQ6TgM0bAMC","colab_type":"code","colab":{}},"source":["history = model.fit(x_train, y_tra,\n","                    batch_size=BATCH_SIZE, epochs=EPOCHS, shuffle=True, validation_data = (x_test, y_tes))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CnHCQMgNbAME","colab_type":"code","colab":{}},"source":["score = model.evaluate(x_test, y_tes)\n","print  (score[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"adAcvj6WbAMG","colab_type":"text"},"source":["Plot graph showing  accuracy  and loss during the training and evaluation"]},{"cell_type":"code","metadata":{"id":"m2eNn2icbAMK","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3KzbbAz3bAMM","colab_type":"code","colab":{}},"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"834BrTiYbAMO","colab_type":"text"},"source":["Evaluate the model performance with test data"]},{"cell_type":"markdown","metadata":{"id":"RxhckVcCbAMO","colab_type":"text"},"source":["**Improving simple net in Keras with more hidden layers (more deep network)**\n","will add more dense layer to the defined network"]},{"cell_type":"code","metadata":{"id":"0whl-y5cbAMO","colab_type":"code","colab":{}},"source":["model = Sequential()\n","model.add(Dense(32, input_dim=(3), activation='relu'))\n","model.add(Dense(32, activation='relu'))\n","# adding three more layers\n","model.add(Dense(16, activation='relu'))\n","model.add(Dense(16, activation='relu'))\n","model.add(Dense(8, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5kvb0QslbAMQ","colab_type":"text"},"source":["**compile,train and validate the model performance**"]},{"cell_type":"code","metadata":{"id":"vCJBKwQqbAMR","colab_type":"code","colab":{}},"source":["model.compile(loss = catergorical, optimizer = SGD,\n","              metrics = accuracy)\n","\n","history1 = model.fit(x_train, y_tra,\n","                    batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data = (x_test, y_tes))\n","\n","# compare and mention the accuracy improvements"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rzl78C21bAMT","colab_type":"code","colab":{}},"source":["score1 = model.evaluate(x_test, y_tes)\n","print  (score1[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ql9XAn0AbAMU","colab_type":"text"},"source":["**Testing different optimizer functions with several hypertuning parameters in Keras**"]},{"cell_type":"markdown","metadata":{"id":"f6dkC3KabAMU","colab_type":"text"},"source":["Let us focus on popular optimizer known as **Stochastic Gradient  Descent (SGD)**\n","Using the Gradient Decent (GD) optimization algorithm, the weights are updated incrementally after each epoch (pass over the training dataset).\n","\n","The loss function J(⋅), the sum of squared errors (SSE), can be written as:"]},{"cell_type":"code","metadata":{"id":"ZgClhGgVhNli","colab_type":"code","colab":{}},"source":["Image('fig/loss_sgd1.png', width=350,height=100)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G7FTXc4BbAMV","colab_type":"text"},"source":["The magnitude and direction of the weight update is computed by taking a step in the opposite direction of the cost gradient"]},{"cell_type":"code","metadata":{"id":"ejC-B9bghZpk","colab_type":"code","colab":{}},"source":["Image('fig/learning_sgd2.png', width=250,height=100)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1PdZtGT2bAMW","colab_type":"text"},"source":["where η is the learning rate and $ \\frac{\\sigma J}{\\sigma wj} $ is partial derivatives"]},{"cell_type":"code","metadata":{"id":"Zp9Spb9Ehlv_","colab_type":"code","colab":{}},"source":["Image('fig/SGD.png', width=650,height=300)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f71Vod4GbAMX","colab_type":"text"},"source":["Essentially, we can picture GD optimization as a hiker (the weight coefficient) who wants to climb down a mountain into a valley , and each step is determined by the steepness of the slope (gradient) and the leg length of the hiker (learning rate). Note thatt if learning rate (η) is too small then hiker will move slowly. if η is too high hiker will possibly miss the value[1]. "]},{"cell_type":"markdown","metadata":{"id":"Pq98KwaQbAMX","colab_type":"text"},"source":["Several learning rate tuning techniques are available,  advanced optimization techniques like **RMSprop**, **Adam**, **Adadelta**, etc. which automaticaly tune parameter."]},{"cell_type":"code","metadata":{"id":"MiXK_d7PbAMY","colab_type":"code","colab":{}},"source":["SGD = keras.optimizers.SGD(lr=0.01, decay = 0.005)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nBzam2OLbAMZ","colab_type":"code","colab":{}},"source":["model.compile(loss = catergorical, optimizer = SGD,\n","              metrics = accuracy)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ujCF-FobAMc","colab_type":"code","colab":{}},"source":["history1 = model.fit(x_train, y_tra,\n","                    batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data = (x_test, y_tes))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XFM9sEvmbAMd","colab_type":"text"},"source":["Train using other advance techniques"]},{"cell_type":"code","metadata":{"id":"nF5ADy6abAMe","colab_type":"code","colab":{}},"source":["SGD = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O92R_OIxbAMh","colab_type":"code","colab":{}},"source":["#SGD = keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6zEJBEqbAMj","colab_type":"code","colab":{}},"source":["model.compile(loss = catergorical, optimizer = SGD,\n","              metrics = accuracy)\n","history1 = model.fit(x_train, y_tra,\n","                    batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data = (x_test, y_tes))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B7znFJtDbAMk","colab_type":"text"},"source":["**Model prediction for unseen data**"]},{"cell_type":"code","metadata":{"id":"3_2j4umrbAMk","colab_type":"code","colab":{}},"source":["x_pred,y_pred = np.load('./dataset/isprs_vaihingen/test/patches/image.npy'),np.load('./dataset/isprs_vaihingen/test/patches/label.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WeIl31e3bAMm","colab_type":"code","colab":{}},"source":["print (x_pred.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tYVns3bubAMn","colab_type":"code","colab":{}},"source":["x_pred = x_pred.reshape(x_pred.shape[0]*x_pred.shape[1]*x_pred.shape[2],x_pred.shape[3])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"arD5SfRvbAMq","colab_type":"code","colab":{}},"source":["print (x_pred.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YJ3MPadNbAMr","colab_type":"code","colab":{}},"source":["Predict_prob = model.predict(x_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"09Y1Km9ybAMs","colab_type":"code","colab":{}},"source":["Predict_prob.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qNiorUIHbAMt","colab_type":"code","colab":{}},"source":["Predict_prob[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WmUwPdnHbAMv","colab_type":"code","colab":{}},"source":["Predict_class = np.argmax(Predict_prob,axis=-1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iePrNZ_AbAMx","colab_type":"code","colab":{}},"source":["Predict_class.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dAZppFvzbAMy","colab_type":"code","colab":{}},"source":["Predict_class = Predict_class.reshape(70,256,256)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SwBKvYHvbAM0","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","import matplotlib.pyplot as  plt\n","fig = plt.figure()\n","ax = fig.add_subplot(121)\n","ax.imshow(Predict_class[4], interpolation='none')\n","ax.set_xticks([])\n","ax.set_yticks([])\n","ax.set_title('Predict')\n","fig.show()\n","\n","ax = fig.add_subplot(122)\n","ax.imshow(y_pred[4], interpolation='none')\n","ax.set_xticks([])\n","ax.set_yticks([])\n","ax.set_title('Label')\n","\n","fig.suptitle('Scene: top_mosaic_09cm_area1')\n","fig.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"33dqvuAQbAM2","colab_type":"text"},"source":["**References**"]},{"cell_type":"markdown","metadata":{"id":"wEUuDyffPoKi","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"xn_AqSBhbAM2","colab_type":"text"},"source":["[1] Bottou, Léon. \"Stochastic gradient descent tricks.\" Neural Networks: Tricks of the Trade. Springer Berlin Heidelberg, 2012. 421-436."]}]}