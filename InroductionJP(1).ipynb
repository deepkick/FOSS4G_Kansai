{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Raw Cell Format","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"InroductionJP.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Gs70XynVWQcM","colab_type":"text"},"source":["# <font color=black> 大規模な地理空間データのディープラーニングの理論と実践 </font>"]},{"cell_type":"markdown","metadata":{"id":"MVrbV84qWQcN","colab_type":"text"},"source":["<center>Lectures: PoliyapramVinayaraj (email: vinay223333@gmail.com) and Ryuhei Hamaguchi (email: ryuhei.hamaguchi@gmail.com )</center></h1>"]},{"cell_type":"markdown","metadata":{"id":"CKZb-o0UWQcO","colab_type":"text"},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{"id":"9j-y1_myWQcP","colab_type":"text"},"source":["音声認識、画像認識、自然言語処理（NLP）、ロボットナビゲーションシステムなどのディープラーニング技術の広範な成長性。"]},{"cell_type":"code","metadata":{"id":"KXfS6IP-W8LB","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8nqyjAksW9_S","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/content/drive/My Drive/FOSS4G_Kansai/')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R9lXkJHlWQcP","colab_type":"text"},"source":["#### 人工知能研究センター（AIRC）の簡単な紹介"]},{"cell_type":"code","metadata":{"id":"D4wBHk6oW9PT","colab_type":"code","colab":{}},"source":["from IPython.display import Image\n","Image(\"fig/AIRC1.png\", width=700, height=425)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UomdPNPZWQcR","colab_type":"text"},"source":["###### 「地球のグローバルモニタリング」と「スマートモビリティ」でAIを活用する"]},{"cell_type":"markdown","metadata":{"id":"TSydRYCoWQcR","colab_type":"text"},"source":["地球観測衛星の革新的な小型化により、数百のマイクロ衛星で構成される「人工衛星群」が実現しました。 結果として生じる大量の地球画像は、人間の目ではなくAIによって自動的に分析されなければなりません。 商業化を促進するために、地球上のあらゆる種類のオブジェクトやイベントを自動検出することにより、膨大な衛星画像から有益な情報を効率的に収集するインテリジェントシステムを開発しています[1]。"]},{"cell_type":"markdown","metadata":{"id":"qaD0yhiFWQcS","colab_type":"text"},"source":["<img src=\"../fig/AIRC2.png\" width=400 >"]},{"cell_type":"code","metadata":{"id":"a1xEJJGmXFxA","colab_type":"code","colab":{}},"source":["Image(\"fig/AIRC2.png\", width=600, height=450)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oymEw0sBWQcS","colab_type":"text"},"source":["### <font color=black>  リモートセンシングのディープラーニング </font>"]},{"cell_type":"markdown","metadata":{"id":"XHvrtdLFWQcT","colab_type":"text"},"source":["データ駆動型の科学と機械学習技術はますます重要になっています。 特に、ディープラーニングは、多くの分野で大きなブレークスルーであり、非常に強力なツールであることが証明されています。 このワークショップの主な目的は、地理空間データアプリケーションのディープラーニングテクニックを紹介することです。"]},{"cell_type":"markdown","metadata":{"id":"b_5nEI_FWQcU","colab_type":"text"},"source":["- リモートセンシングデータは、多くの場合、マルチモーダルです（例：光学（マルチおよびハイパースペクトル）、ライダー、および合成開口レーダー（SAR）センサーから）\n","- リモートセンシングデータは地理的に配置されています。つまり、自然に地理空間に配置されています。\n","- 時系列処理をトリガーする連続的および時間的観測\n","- リモートセンシングも「ビッグデータ」の課題に直面しています"]},{"cell_type":"markdown","metadata":{"id":"XaM8GpjkWQcU","colab_type":"text"},"source":["### <font color=black> 一般的なアプリケーション </font>"]},{"cell_type":"markdown","metadata":{"id":"XswzO2K3WQcV","colab_type":"text"},"source":[">  **ハイパースペクトル画像分析, \n","   SAR画像の分類, \n","  マルチモーダルデータ融合, 物体検出,\n","  3-D 再構築,\n","  ノイズリダクション,\n","  ドメイン適応, 次元削減, etc.**"]},{"cell_type":"markdown","metadata":{"id":"JzOeoOouWQcV","colab_type":"text"},"source":["### 1. パーセプトロン学習"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"XQd105zkWQcW","colab_type":"text"},"source":["パーセプトロンは、入力機能と呼ばれる入力ベクトルx（x1、x2、..、xn）を与え、1または0を出力する、直感的で実装が容易な機械学習アルゴリズムです。パーセプトロンは、教師あり学習アルゴリズムのカテゴリに属します。 より具体的には、単層バイナリ分類器。 パーセプトロンアルゴリズムは、線形に分離可能な2つのクラスを区別できる線形決定境界を描画するために、入力フィーチャの重みを学習することです。"]},{"cell_type":"markdown","metadata":{"id":"wJkoZj1uWQcX","colab_type":"text"},"source":[" **単層パーセプトロン**  "]},{"cell_type":"code","metadata":{"id":"Y_MXxfgyXP9m","colab_type":"code","colab":{}},"source":["Image(\"fig/SLP.png\", width=800, height=400)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uM43xmNoWQcY","colab_type":"text"},"source":["<center>$ Net =  w_1 x_1  +w_2 x_2  + w_3 x_3  + ... + w_m x_m  + b $ </center></h1>"]},{"cell_type":"markdown","metadata":{"id":"hxTLN441WQcY","colab_type":"text"},"source":["ここで、「Net」は正味積、「w」は重み、「x」は特徴（マルチスペクトル画像「x」がスペクトルバンドである場合）、「b」はバイアスです[2]"]},{"cell_type":"markdown","metadata":{"id":"BPDIFipLWQcZ","colab_type":"text"},"source":["\\begin{equation*}\n","Net =  \\sum_{i=0}^m w_i x_i + b \n","\\end{equation*}"]},{"cell_type":"markdown","metadata":{"id":"qLwiKy2WWQcZ","colab_type":"text"},"source":["**Kerasのいくつかの例を使用してこれを確認しましょう**"]},{"cell_type":"code","metadata":{"id":"xQmE4W71WQca","colab_type":"code","colab":{}},"source":["import numpy as np\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Activation, Dense"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dsbQdwgAWQcd","colab_type":"text"},"source":["5つの入力変数（スペクトルバンド）があるとします"]},{"cell_type":"code","metadata":{"id":"Te3Ojz8xWQce","colab_type":"code","colab":{}},"source":["model = Sequential()\n","model.add(Dense(1, input_dim=5, kernel_initializer='random_uniform'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MVZY6aI-WQcg","colab_type":"text"},"source":["各ニューロンは、ランダムな重み、「random_uniform」、「random_normal」、ゼロなどの初期化するいくつかの\n","オプションで初期化できます。"]},{"cell_type":"code","metadata":{"id":"hooShNYpWQcg","colab_type":"code","colab":{}},"source":["print (model.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4AgfrZaAWQci","colab_type":"text"},"source":["初期化されたパラメーター（重みとバイアス）を確認しましょう"]},{"cell_type":"code","metadata":{"id":"doqMoGYHWQcj","colab_type":"code","colab":{}},"source":["weights_bias = model.layers[0].get_weights()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o2No7n0cWQck","colab_type":"code","colab":{}},"source":["print (weights_bias)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8bVGgjdXWQcm","colab_type":"text"},"source":["**多層パーセプトロン**"]},{"cell_type":"code","metadata":{"id":"v34yWrluXV1j","colab_type":"code","colab":{}},"source":["Image(\"fig/MLP.png\", width=1000, height=500)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FDl3TqbbWQcn","colab_type":"text"},"source":["**ニューラルネットワークのサイズ設定：** ニューラルネットワークのサイズを測定するために一般的に使用される2つのメトリックは、ニューロンの数、またはより一般的にはパラメーターの数です。 上の図の2つのネットワーク例での作業[3]\n","\n","第1ネットワーク（左）は 4 + 2 = 6 ニューロン（入力をカウントしない）, [3 x 4] + [4 x 2] = 20 ウエイトと 4 + 2 = 6 バイアス, 合計26個の学習可能なパラメーターを持ちます。\n","第2ネットワーク（右）は  4 + 4 + 1 = 9 ニューロン, [3 x 4] + [4 x 4] + [4 x 1] = 12 + 16 + 4 = 32 ウエイトと 4 + 4 + 1 = 9 バイアス,  合計41個の学習可能なパラメーターを持ちます。 "]},{"cell_type":"markdown","metadata":{"id":"EW-wvAmTWQco","colab_type":"text"},"source":["\\begin{equation*}\n"," Net_j = \\sum_{i=0}^m w_ji x_i + b \n","\\end{equation*}"]},{"cell_type":"markdown","metadata":{"id":"pIqMKo48WQco","colab_type":"text"},"source":["<center> Where, $ Net_j $ 隠れレイヤーの各ニューロンのネット積です。 <center>"]},{"cell_type":"markdown","metadata":{"id":"uzYaQjNqWQcp","colab_type":"text"},"source":["**Kerasのいくつかの例を使用してこれを確認しましょう**"]},{"cell_type":"code","metadata":{"id":"0ZUnjczOWQcp","colab_type":"code","colab":{}},"source":["model = Sequential()\n","model.add(Dense(4, input_dim=3, kernel_initializer='random_uniform'))\n","model.add(Dense(2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kfnFdzH0WQcr","colab_type":"code","colab":{}},"source":["weights_bias0 = model.layers[0].get_weights()\n","weights_bias1 = model.layers[1].get_weights()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wuzGMvPzWQcx","colab_type":"code","colab":{}},"source":["print (weights_bias0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W0xw2wuDWQcz","colab_type":"code","colab":{}},"source":["print (weights_bias1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pWN0g_XQWQc1","colab_type":"text"},"source":["**参照**"]},{"cell_type":"markdown","metadata":{"id":"pOkHImteWQc2","colab_type":"text"},"source":["1. National Institute of Advanced Industrial Science and Technology\n","2. F.ROSENBLATT, THE PERCEPTRON: A PROBABILISTIC MODEL FOR INFORMATION STORAGE AND ORGANIZATION IN THE BRAIN\n","3. http://cs231n.github.io"]}]}