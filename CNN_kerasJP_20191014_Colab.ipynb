{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "CNN_kerasJP.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepkick/FOSS4G_Kansai/blob/master/CNN_kerasJP_20191014_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPlN3mlGP_ZX",
        "colab_type": "text"
      },
      "source": [
        "## 畳み込みニューラルネットワーク（CNN）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbDm0cgRQWw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybdjLeo4QbXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/FOSS4G_DeepLearning_HandsOn_datasets/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZh1DiW7P_ZZ",
        "colab_type": "text"
      },
      "source": [
        "畳み込みとは？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTA21K_oQevt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6BJG5j_QjNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "Image('fig/cnn1.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsgfS4cjP_Za",
        "colab_type": "text"
      },
      "source": [
        "32 $*$ 32ピクセル（長さと幅）3スペクトルバンド（3チャンネル）、5 $*$ 5 kernel_sizeサイズ[1]の画像の例です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGTPkftpP_Zb",
        "colab_type": "text"
      },
      "source": [
        "下の図は、それがどのように正確に機能するかを示しています"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSOL-lXLQsLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('fig/cnn2.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9O4xXfPP_Zc",
        "colab_type": "text"
      },
      "source": [
        "各フィルターは、独立して画像と畳み込まれ、ユーザーが定義した数の機能になります。 次の図では、6つのフィルターから派生した6つのフィーチャ表現があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4VkkianQwxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('fig/cnn3.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI6Cao5KP_Ze",
        "colab_type": "text"
      },
      "source": [
        "ここで、CNNは定義された数の畳み込み層（ブロック）のコレクションであり、1つの層からの畳み込み（機能）結果は、次の図に示すように入力として次の層に渡されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4hdVauWQxsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('fig/cnn4.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YY2tzpLP_Zf",
        "colab_type": "text"
      },
      "source": [
        "**Kerasを使用して独自のシンプルなCNNを作成して、詳細を見てみましょう**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7AJ3qy8P_Zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "x_train,y_train = np.load('./isprs_vaihingen/train/patches/image.npy'),np.load('./isprs_vaihingen/train/patches/label.npy')\n",
        "x_test,y_test = np.load('./isprs_vaihingen/val/patches/image.npy'),np.load('./isprs_vaihingen/val/patches/label.npy')\n",
        "channel = x_train.shape[-1]\n",
        "num_classes = 5\n",
        "img_rows, img_cols = 256, 256\n",
        "input_shape = (img_rows, img_cols, channel)\n",
        "y_tra = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_tes = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSvqh-z1P_Zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense,Input,Activation,Conv2D, MaxPooling2D,UpSampling2D, Dropout,Conv2DTranspose, concatenate, Flatten,BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udAQhIH6P_Zk",
        "colab_type": "text"
      },
      "source": [
        "**フィルター**、**カーネルサイズ**、**パディング**、**ストライド**、**プーリング**および生成された**パラメーター**の数を確認してください"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Cmzq8QUP_Zl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = (256, 256, 3)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 10, kernel_size = (5,5), strides =1,padding = 'valid', \n",
        "                 input_shape=input_shape, activation='relu'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rctwsMBzP_Zn",
        "colab_type": "text"
      },
      "source": [
        "**パディングとは**  ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f67KHofNP_Zo",
        "colab_type": "text"
      },
      "source": [
        "**パディング**は、畳み込み後の画像の元の形状を保持するために、画像の外側に余分なピクセルを追加することです[2]。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2yaVx93Q9dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./fig/no_padding_no_strides.gif','rb') as f:\n",
        "    display(Image(data=f.read(),width=400,height=500, format='png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04TKn4uCRAf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./fig/arbitrary_padding_no_strides.gif','rb') as f:\n",
        "    display(Image(data=f.read(), format='png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe6_12a6P_Zq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 10, kernel_size = (5,5), strides = 1, padding = 'same', \n",
        "                 input_shape=input_shape, activation='relu'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7YHGv0TP_Zu",
        "colab_type": "text"
      },
      "source": [
        "**ストライド**は、カーネルの畳み込みに使用されるピクセルの単位です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-ZtGHgtRFtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./fig/no_padding_strides.gif','rb') as f:\n",
        "    display(Image(data=f.read(), width=400,height=500, format='png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifW2wTRFRImV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./fig/padding_strides.gif','rb') as f:\n",
        "    display(Image(data=f.read(), width=400,height=500, format='png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOy7OZTsP_Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 10, kernel_size = (5,5), strides = 2, padding = 'same', \n",
        "                 input_shape=input_shape, activation='relu'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu1SLqoGP_Zy",
        "colab_type": "text"
      },
      "source": [
        "**プールレイヤー**は、各入力フィーチャで独立してボリュームを空間的にダウンサンプリングします。 この関数は、空間サイズを縮小するために使用し、したがってパラメーターと計算の数を減らします。 例：maxpool、averagepool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhJa9IA4RNCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('fig/pooling.png', width=800, height=350)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KQ6LGobP_Zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 10, kernel_size = (5,5), strides = 1, padding = 'same', \n",
        "                 input_shape=input_shape, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_qjgNnlP_Z1",
        "colab_type": "text"
      },
      "source": [
        "**Kerasで Encoder-decoder CNNネットワークを構築**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKFr5s5FP_Z1",
        "colab_type": "text"
      },
      "source": [
        "これはCNNネットワークで、エンコーダーネットワーク、対応するデコーダーネットワーク、それに続くピクセル単位の分類レイヤーで構成されます。Segnet、U-net、Deconv-netなど、いくつかの有名なエンコーダーデコーダーが利用可能です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skx7e3OCP_Z2",
        "colab_type": "text"
      },
      "source": [
        "独自のシンプルなEncoder-decoderネットワークを定義しましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaHdmBCjP_Z2",
        "colab_type": "text"
      },
      "source": [
        "まず、エンコーダー部分を定義します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw_m8BOwP_Z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = Input((input_shape))\n",
        "conv1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool1)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcVEzBoMP_Z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.backend.int_shape(pool2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGIr9LJSP_Z7",
        "colab_type": "text"
      },
      "source": [
        "デコーダー部分を定義する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E_0gR08P_Z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool2)\n",
        "up1 = UpSampling2D(size=(2, 2),interpolation='nearest')(conv3)\n",
        "conv4 = Conv2D(16, (3, 3), activation='relu', padding='same')(up1)\n",
        "up2 = UpSampling2D(size=(2, 2),interpolation='nearest')(conv4)\n",
        "conv5 = Conv2D(num_classes, (1, 1), activation='softmax')(up2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyCKkL15P_Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.backend.int_shape(conv5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH5dCm_xP_aA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[inputs], outputs=[conv5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKCTIl43P_aC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MHzypE5P_aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE= 32\n",
        "EPOCHS = 2\n",
        "#SGD = keras.optimizers.SGD(lr=0.01)\n",
        "SGD = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "catergorical = keras.losses.categorical_crossentropy\n",
        "accuracy = ['accuracy']\n",
        "model.compile(loss = catergorical, optimizer = SGD,\n",
        "              metrics = accuracy)\n",
        "\n",
        "history1 = model.fit(x_train, y_tra,\n",
        "                    batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data = (x_test, y_tes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XBINm6SP_aI",
        "colab_type": "text"
      },
      "source": [
        "予測のためのデータの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2Pl5Hf4P_aJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_pred,y_pred = np.load('./isprs_vaihingen/test/patches/image.npy'),np.load('./isprs_vaihingen/test/patches/label.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QYAtP1dP_aM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Predict_prob = model.predict(x_pred)\n",
        "Predict_prob.shape\n",
        "Predict_class = np.argmax(Predict_prob,axis=-1)\n",
        "Predict_class.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6ziqzffP_aO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2meYzJfP_aR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as  plt\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(121)\n",
        "ax.imshow(Predict_class[4], interpolation='none')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.set_title('Predict')\n",
        "fig.show()\n",
        "\n",
        "ax = fig.add_subplot(122)\n",
        "ax.imshow(y_pred[4], interpolation='none')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.set_title('Label')\n",
        "\n",
        "fig.suptitle('Scene: top_mosaic_09cm_area1')\n",
        "fig.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OclR0BU1P_aT",
        "colab_type": "text"
      },
      "source": [
        "**U-net; 深い畳み込みネットワーク**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOUPVXr9P_aT",
        "colab_type": "text"
      },
      "source": [
        "U-netは、U字型のエンドツーエンドネットワークです。 U-netは、縮小パス（左側）と拡張パス（右側）で構成されています。 U-netには、ダウンサンプリングプロセスで失われた機能をアップサンプリングプロセスで適切な機能と連結する特別なアーキテクチャがあります。 この特定の側面により、U-netはエレガントな深層学習ネットワークとして機能します[3]。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKl19EP7TMxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('fig/Unet.png', width=600, height = 400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0tJ4rXGP_aU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = Input((input_shape))\n",
        "# Encoder\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "conv1 = BatchNormalization()(conv1)\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "conv2 = BatchNormalization()(conv2)\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "conv3 = BatchNormalization()(conv3)\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "conv4 = BatchNormalization()(conv4)\n",
        "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "# Decoder\n",
        "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "conv6 = BatchNormalization()(conv6)\n",
        "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "conv7 = BatchNormalization()(conv7)\n",
        "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "conv8 = BatchNormalization()(conv8)\n",
        "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "conv9 = BatchNormalization()(conv9)\n",
        "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "conv10 = Conv2D(num_classes, (1, 1), activation='softmax')(conv9)\n",
        "model = Model(inputs=[inputs], outputs=[conv10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBYCj2QuP_aW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE= 24\n",
        "EPOCHS = 1\n",
        "#SGD = keras.optimizers.SGD(lr=0.01)\n",
        "SGD = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "catergorical = keras.losses.categorical_crossentropy\n",
        "accuracy = ['accuracy']\n",
        "model.compile(loss = catergorical, optimizer = SGD,\n",
        "              metrics = accuracy)\n",
        "\n",
        "history1 = model.fit(x_train, y_tra,\n",
        "                    batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data = (x_test, y_tes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwhgdngkP_aX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "model_json = model.to_json()\n",
        "with open(\"./learned_weights/demo_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"./learned_weights/demo_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXnbQv-GP_aZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Predict_prob = model.predict(x_pred)\n",
        "Predict_prob.shape\n",
        "Predict_class = np.argmax(Predict_prob,axis=-1)\n",
        "Predict_class.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2pJtQsfSP_ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(121)\n",
        "ax.imshow(Predict_class[1], interpolation='none')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.set_title('Predict')\n",
        "fig.show()\n",
        "\n",
        "ax = fig.add_subplot(122)\n",
        "ax.imshow(y_pred[1], interpolation='none')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.set_title('Label')\n",
        "\n",
        "fig.suptitle('Scene: top_mosaic_09cm_area1')\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKuYgxiaP_af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import h5py\n",
        "json_file = open('./learned_weights/model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"./learned_weights/model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoP1xqGnP_ag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Predict_prob = loaded_model.predict(x_pred)\n",
        "Predict_prob.shape\n",
        "Predict_class = np.argmax(Predict_prob,axis=-1)\n",
        "Predict_class.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcSRBtoXP_ai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(121)\n",
        "ax.imshow(Predict_class[1], interpolation='none')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.set_title('Predict')\n",
        "fig.show()\n",
        "\n",
        "ax = fig.add_subplot(122)\n",
        "ax.imshow(y_pred[1], interpolation='none')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.set_title('Label')\n",
        "\n",
        "fig.suptitle('Scene: top_mosaic_09cm_area1')\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oUs4jWQP_aj",
        "colab_type": "text"
      },
      "source": [
        "**参照**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAkXgl9wP_ak",
        "colab_type": "text"
      },
      "source": [
        "1. Harsh Pokharna, The best explanation of Convolutional Neural Networks on the Internet\n",
        "2. Vincent Dumoulin, Francesco Visin - A guide to convolution arithmetic for deep learning (BibTeX)\n",
        "3. Olaf Ronneberger, Philipp Fischer, Thomas Brox, U-Net: Convolutional Networks for Biomedical Image Segmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_XfzNLiOzPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}