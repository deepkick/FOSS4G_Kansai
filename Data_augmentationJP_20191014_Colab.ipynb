{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Data_augmentationJP.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepkick/FOSS4G_Kansai/blob/master/Data_augmentationJP_20191014_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLSyKpcMSsd5",
        "colab_type": "text"
      },
      "source": [
        "# 内容\n",
        "## PyTorchの基本\n",
        "- ネットワークアーキテクチャの定義\n",
        "- データセットとデータローダー\n",
        "- トレーニング\n",
        "- 推論\n",
        "\n",
        "## データ増強\n",
        "- データ増強"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58l--y6XSsd6",
        "colab_type": "text"
      },
      "source": [
        "## マサチューセッツ州の建物のデータセット\n",
        "このチュートリアルでは、建物の検出にデータセットを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnMPPGfXT274",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSYPMNl2T5Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/FOSS4G_DeepLearning_HandsOn_datasets/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-1b17L9Ssd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image  as  ImgPIL\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "fpath_image = './building_vmnih/test/image/22828930_15.tiff'\n",
        "fpath_label = './building_vmnih/test/label/22828930_15.tif'\n",
        "\n",
        "image = np.array(ImgPIL.open(fpath_image))\n",
        "label = np.array(ImgPIL.open(fpath_label))\n",
        "\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.imshow(image, interpolation='none')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "fig.show()\n",
        "ax.set_title('Source image')\n",
        "\n",
        "ax = fig.add_subplot(122)\n",
        "ax.imshow(label, interpolation='none')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.set_title('Ground truth')\n",
        "\n",
        "fig.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8ur2SnqSsd-",
        "colab_type": "text"
      },
      "source": [
        "データセットでは、137組の画像と上記のようなラベルがトレーニング用に提供されています。データセットでモデルをトレーニングする前に、pytorchの基本について説明します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQtTxJABSsd_",
        "colab_type": "text"
      },
      "source": [
        "##  PyTorchの基本\n",
        "PyTorchは、Facebookが開発した有名なディープラーニングフレームワークです。ここでは、PyTorchの基本を紹介します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMuAbSX-Ssd_",
        "colab_type": "text"
      },
      "source": [
        "次に、pytorchモジュールをインポートします。 <br>\n",
        "`torch.nn`には、畳み込み、プーリング、バッチ正規化など、さまざまな種類の操作のクラスが含まれます。<br>\n",
        "`torch.nn.functional`には、アクティベーション関数などの基本的な（およびノンパラメトリックな）操作のための関数が含まれています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExUF3alSSseA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo7NjAtpSseC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Umzi4rojSseE",
        "colab_type": "text"
      },
      "source": [
        "### PyTorchのテンソル\n",
        "テンソルはさまざまな方法で作成できます。 テンソルは、numpy配列のように使用できます。\n",
        "```\n",
        "torch.FloatTensor([1,2,3])\n",
        "torch.from_numpy(ndarray)\n",
        "torch.Tensor([1,2,3]).float()\n",
        "```\n",
        "\n",
        "### 基本操作\n",
        "ネットワークを実装する前に、畳み込みやプーリングなどの基本操作を定義する方法を簡単に確認します。 <br><br>\n",
        "\n",
        "**畳み込み層**<br>\n",
        "畳み込み層はクラス（ `nn.Conv2d`）として実装されます。 最初にレイヤーのインスタンスを作成し、それを関数のように使用します。\n",
        "```\n",
        "conv1 = torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "output = conv1(input)\n",
        "```\n",
        "\n",
        "**プール層**\n",
        "```\n",
        "pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "output = pool1(input)\n",
        "\n",
        "pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "output = pool2(input)\n",
        "```\n",
        "\n",
        "**完全に接続されたレイヤー**\n",
        "```\n",
        "fc1 = torch.nn.Linear(in_features=128, out_features=128)\n",
        "output = fc1(input)\n",
        "```\n",
        "\n",
        "**アクティベーション機能**<br>\n",
        "アクティベーションは関数として実装されます。\n",
        "```\n",
        "output = torch.nn.functional.relu(input)\n",
        "```\n",
        "クラスバージョンも使用できます。\n",
        "```\n",
        "act1 = torch.nn.ReLU()\n",
        "output = act1(input)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCbHD3K0SseF",
        "colab_type": "text"
      },
      "source": [
        "### ネットワークアーキテクチャの定義\n",
        "上記の基本操作を使用して、入力として$64\\times64$パッチを持つVGGのようなモデルを実装し、サイズ$16\\times16$の中心領域の推定値を出力します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-_EYEJ8SseG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class VGGS(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGGS, self).__init__()\n",
        "        self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv1_2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.pool1   = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2_1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv2_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.pool2   = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv3_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.pool3   = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv4_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv4_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.pool4   = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc6 = nn.Linear(in_features=4096, out_features=1024)\n",
        "        self.fc7 = nn.Linear(in_features=1024, out_features=1024)\n",
        "        self.fc8 = nn.Linear(in_features=1024, out_features=256)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1_1(x))\n",
        "        x = F.relu(self.conv1_2(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv2_1(x))\n",
        "        x = F.relu(self.conv2_2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv3_1(x))\n",
        "        x = F.relu(self.conv3_2(x))\n",
        "        x = self.pool3(x)\n",
        "        x = F.relu(self.conv4_1(x))\n",
        "        x = F.relu(self.conv4_2(x))\n",
        "        x = self.pool4(x)\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        x = x.view(batch_size, -1)\n",
        "        \n",
        "        x = F.dropout(self.fc6(x))\n",
        "        x = F.dropout(self.fc7(x))\n",
        "        x = self.fc8(x)\n",
        "        x = x.view(batch_size, 16, 16)\n",
        "        return x\n",
        "    \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Nz7IGQuSseJ",
        "colab_type": "text"
      },
      "source": [
        "モデルを作成し、アーキテクチャを確認する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj4tmPOlSseJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = VGGS()\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1of56QwVSseL",
        "colab_type": "text"
      },
      "source": [
        "ランダムテンソルを処理して、アーキテクチャが正しいかどうかを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmbRGp-lSseM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = np.random.randn(100,3,64,64).astype(np.float32)\n",
        "inputs = torch.from_numpy(inputs)\n",
        "output = model(inputs)\n",
        "print(output.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkCCQclESseO",
        "colab_type": "text"
      },
      "source": [
        "### 損失関数\n",
        "ここでは、トレーニングのクロスエントロピー損失関数を定義します。 `log()`でのオーバーフローを避けるために、小さな値`eps`が必要です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr31cmsiSseO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Criterion(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Criterion, self).__init__()\n",
        "        self.eps = 1.0e-7\n",
        "        \n",
        "    def forward(self, inputs, targets):\n",
        "        prob = F.sigmoid(inputs)\n",
        "        loss = -targets.float()*(prob + self.eps).log() - (1-targets.float())*(1 - prob + self.eps).log()\n",
        "        loss = loss.mean()\n",
        "        return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uTpO7pLSseQ",
        "colab_type": "text"
      },
      "source": [
        "## データセットとデータローダー\n",
        "以下の図は、トレーニング用のミニバッチがPyTorchでどのように作成されるかを示しています。 <br>\n",
        "**DataLoader**: DataLoaderはDatasetからデータを取得し、収集したデータをミニバッチにパックします。 <br>\n",
        "**Dataset**: データローダから要求されたデータセットのロードと前処理データ。 場合によっては、独自のデータ用にカスタマイズされたデータセットを実装する必要があります。 <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMIYD6AqUN2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "Image('fig/pth_dataset.png',  height=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36emffNhSseR",
        "colab_type": "text"
      },
      "source": [
        "### 独自のデータセットを定義する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IV7kTztSseS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class Buildings(Dataset):\n",
        "    def __init__(self, fpath_image_npy, fpath_label_npy):\n",
        "        self.images = np.load(fpath_image_npy)\n",
        "        self.labels = np.load(fpath_label_npy)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        label = self.labels[index]\n",
        "        \n",
        "        image = image.transpose([2,0,1])    # (H,W,B) to (B,H,W)\n",
        "        \n",
        "        image_tensor = torch.from_numpy(image).float()\n",
        "        label_tensor = torch.from_numpy(label).long()\n",
        "        \n",
        "        return image_tensor, label_tensor\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh4NeB4hSseU",
        "colab_type": "text"
      },
      "source": [
        "建物データセットを読み込む"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYfn7zwMSseV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = Buildings('./building_vmnih/train/patches/sat.npy', './building_vmnih/train/patches/map.npy')\n",
        "image_tensor, label_tensor = dataset[0]\n",
        "print(image_tensor.size())\n",
        "print(label_tensor.size())\n",
        "print(len(dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojBMgEsUSseW",
        "colab_type": "text"
      },
      "source": [
        "次に、DataLoaderを設定し、機能するかどうかを確認します。 <br><br>\n",
        "DataLoaderのinitの引数: <br>\n",
        "batch_size: batch_sizeを指定します<br>\n",
        "shuffle: Trueの場合、データはDatasetからランダムにサンプリングされ、Falseの場合、データは順次サンプリングされます。<br>\n",
        "num_workers: マルチスレッドワーカーの数。 データを並行してロードできるため、データのロードが高速化されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCGCwIu_SseX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset, batch_size=10, shuffle=True, num_workers=0)\n",
        "for image, label in loader:\n",
        "    print(image.size(), torch.mean(image).item())\n",
        "    print(label.size(), label[0,0,0].item())\n",
        "    print('')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi8mfGKDSsea",
        "colab_type": "text"
      },
      "source": [
        "### トレーニング"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F7icguGSsea",
        "colab_type": "text"
      },
      "source": [
        "ここで、トレーニングデータローダーを準備しました。 以下では、トレーニング手順を簡単に示します。 完全なトレーニングには多くの時間がかかるため、最初のいくつかの反復を示します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts_tq8HvSseb",
        "colab_type": "text"
      },
      "source": [
        "デバイスを設定します。 この場合、 \"cpu\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0ty7TNajSseb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnouMZ2rSsed",
        "colab_type": "text"
      },
      "source": [
        "トレーニングする最大エポックを設定します。 デモンストレーションのために、max_epochs 1を設定しますが、数十個のエポックを使用することをお勧めします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHVlvMmqSsee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_epochs = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wueSP7RrSsef",
        "colab_type": "text"
      },
      "source": [
        "モデルをデバイスに転送"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QWxAkNCSseg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ6modF5Ssei",
        "colab_type": "text"
      },
      "source": [
        "オプティマイザーを設定します。 ここでは、Adamを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRz3_bQRSsei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9,0.999), weight_decay=1.0e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHwmHG4PSsel",
        "colab_type": "text"
      },
      "source": [
        "損失関数を設定し、デバイスに転送します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AejGSdGNSsen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = Criterion().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X7RDu6wSsep",
        "colab_type": "text"
      },
      "source": [
        "トレーニングの繰り返し。 いくつかの反復のみを示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxPJ-KJySseq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(max_epochs):\n",
        "    for idx, (image, label) in enumerate(loader):\n",
        "        image, label = image.to(device), label.to(device)\n",
        "        \n",
        "        # At the begining of each iteraton, clear accumulated gradient for the network parameters.\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Input the image to the model and get the prediction.\n",
        "        output = model(image)\n",
        "        \n",
        "        # Calculate the loss function comparing the prediction and the ground truth\n",
        "        loss = criterion(output, label)\n",
        "        \n",
        "        # Backpropagate the error signal through the model to calculate gradients.\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update the model parameters using the calculated gradients.\n",
        "        optimizer.step()\n",
        "\n",
        "        print('Epoch #%d, batch #%d: loss=%f' % (epoch, idx, loss.item()))\n",
        "        \n",
        "        # For demonstration, stop iteration at iter5\n",
        "        if idx == 4:\n",
        "            break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wwg-WLpSser",
        "colab_type": "text"
      },
      "source": [
        "### 学習したモデルを保存する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyp7Z-YcSses",
        "colab_type": "text"
      },
      "source": [
        "出力ディレクトリを設定する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I4e87b6Sset",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "output_dir = './learned_weights/'\n",
        "\n",
        "if not os.path.isdir(output_dir):\n",
        "    os.mkdir(output_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi2eatOBSsev",
        "colab_type": "text"
      },
      "source": [
        "学習した重みをdictionaryとして取得します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8q3L9z1Ssew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_weights = model.state_dict()\n",
        "for key, weight in dict_weights.items():\n",
        "    print('%s\\t%s' % (key, weight.size()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgprNAXKSsex",
        "colab_type": "text"
      },
      "source": [
        "dictionaryを保存します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7LiylHESsey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(dict_weights, output_dir + '/demo_building_vggs.torch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx5mAZnfSse0",
        "colab_type": "text"
      },
      "source": [
        "### 推論"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwGy3vuQSse1",
        "colab_type": "text"
      },
      "source": [
        "設定。 切り取りウィンドウを16ストライドずつスライドさせて、テスト画像を切り取ります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMGS1L8CSse1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patch_size = 64\n",
        "aoi_size = 16\n",
        "stride = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S8EXshMUqlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('fig/fig_test_patch_small.png', width=450)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SppqS3USse4",
        "colab_type": "text"
      },
      "source": [
        "テスト領域の画像を準備する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaGHPLdoSse5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "use_cuda = False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "from PIL import Image as ImgPIL\n",
        "# Load image\n",
        "fpath_test_image = './building_vmnih/test/image/22828930_15.tiff'\n",
        "image = np.array(ImgPIL.open(fpath_test_image))\n",
        "org_height, org_width, _ = image.shape\n",
        "\n",
        "# Normalize\n",
        "mean = np.mean(image, axis=(0,1), keepdims=True)\n",
        "std = np.std(image, axis=(0,1), keepdims=True)\n",
        "image = (image - mean) / std\n",
        "\n",
        "# To tensor\n",
        "image = image.transpose([2,0,1])    # Swap dimensions, (H,W,B) to (B,H,W)\n",
        "image = image[np.newaxis,:,:,:]    # Add batch dimension (N,B,H,W)\n",
        "image = torch.from_numpy(image).float()    # Convert to float tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVEeLHW9Sse6",
        "colab_type": "text"
      },
      "source": [
        "ネットワークは入力パッチの中央領域の推定結果を出力するため、画像のエッジ領域を推定するために、入力パッチの一部が有効な画像領域外にあります。 したがって、パディングを使用して元の画像を拡大する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmeeMGKSU1O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('fig/fig_test_padding_small.png', width=600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DZWq7XMbSse7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reflection padding\n",
        "pad_size = int((64-16)/2)\n",
        "pad = nn.ReflectionPad2d(pad_size)\n",
        "image = pad(image)\n",
        "_, _, height, width = image.size()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-ad8zmKSse9",
        "colab_type": "text"
      },
      "source": [
        "モデルを設定し、トレーニング済みの重みを読み込む"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_ZNJgIkSse-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set model\n",
        "model = VGGS().to(device)\n",
        "\n",
        "# Load learned weights\n",
        "learned_weights = torch.load('./learned_weights/demo_building_vggs.torch')\n",
        "model.load_state_dict(learned_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMfxdz89SsfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Set place holder\n",
        "prob_map = np.zeros([height, width])\n",
        "count_map = np.zeros([height, width])\n",
        "\n",
        "# Crop patches in sliding manner, and apply the prediction model\n",
        "num_tiles_x = (width - patch_size) // stride + 2\n",
        "num_tiles_y = (height - patch_size) // stride + 2\n",
        "\n",
        "for iy in range(num_tiles_y):\n",
        "    for ix in range(num_tiles_x):\n",
        "        print('(%d/%d, %d/%d)' % (iy, num_tiles_y, ix, num_tiles_x))\n",
        "        ulx = ix * stride\n",
        "        uly = iy * stride\n",
        "        lrx = ulx + patch_size\n",
        "        lry = uly + patch_size\n",
        "        \n",
        "        if lrx > width:\n",
        "            ulx = width - patch_size\n",
        "            lrx = width\n",
        "            \n",
        "        if lry > height:\n",
        "            uly = height - patch_size\n",
        "            lry = height\n",
        "            \n",
        "        patch = image[:, :, uly:lry, ulx:lrx]\n",
        "        patch = patch.to(device)\n",
        "        \n",
        "        logit = model(patch)\n",
        "        prob = F.sigmoid(logit)\n",
        "        \n",
        "        stx = ulx + int((patch_size - aoi_size) / 2)\n",
        "        sty = uly + int((patch_size - aoi_size) / 2)\n",
        "        prob_map[sty:sty+aoi_size, stx:stx+aoi_size] += prob.detach().cpu().numpy().squeeze()\n",
        "        count_map[sty:sty+aoi_size, stx:stx+aoi_size] += np.ones([aoi_size,aoi_size])\n",
        "\n",
        "# Eliminate padded region\n",
        "prob_map = prob_map[pad_size:pad_size+org_height, pad_size:pad_size+org_width]\n",
        "count_map = count_map[pad_size:pad_size+org_height, pad_size:pad_size+org_width]\n",
        "\n",
        "# Take average for overlaped regions\n",
        "result = prob_map / count_map\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jmg3hwXSsfD",
        "colab_type": "text"
      },
      "source": [
        "推定結果を確認する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjDXlrtpSsfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "fpath_test_label = './building_vmnih/test/label/22828930_15.tif'\n",
        "label = np.array(ImgPIL.open(fpath_test_label))[:,:,0]\n",
        "\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.imshow(result, interpolation='none')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "fig.show()\n",
        "ax.set_title('Estimation')\n",
        "\n",
        "ax = fig.add_subplot(122)\n",
        "ax.imshow(label, interpolation='none')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.set_title('Ground truth')\n",
        "\n",
        "fig.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OrecAnUSsfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "pred = (result > 0.5)\n",
        "label = (label > 0.5)\n",
        "\n",
        "TP = np.sum(pred*label)\n",
        "T = np.sum(label)\n",
        "P = np.sum(pred)\n",
        "IoU = float(TP) / (T+P-TP) * 100\n",
        "print('IoU: %.2f%%' % IoU)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdBmEJoqSsfJ",
        "colab_type": "text"
      },
      "source": [
        "次に、Datasetクラスにデータ拡張（ランダムな回転と反転）を追加します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT2Qx053SsfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "from PIL import Image as ImgPIL\n",
        "\n",
        "class Buildings(Dataset):\n",
        "    def __init__(self, fpath_image_npy, fpath_label_npy, augmentation=False):\n",
        "        self.images = np.load(fpath_image_npy)\n",
        "        self.labels = np.load(fpath_label_npy)\n",
        "        self.augmentation = augmentation\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        label = self.labels[index]\n",
        "        \n",
        "        # Augmentation\n",
        "        if self.augmentation:\n",
        "            # Randomly choose rotation angle and flipping direction\n",
        "            rotation = random.choice([0, 90, 180, 270])\n",
        "            flip = random.choice(['H', 'V', 'N'])\n",
        "            \n",
        "            # Apply transformation for image\n",
        "            image = self._rotate(image, rotation)\n",
        "            image = np.array(self._flip(image, flip))\n",
        "\n",
        "            # Also, apply the same transformation for label\n",
        "            label = self._rotate(label, rotation)\n",
        "            label = np.array(self._flip(label, flip))\n",
        "        \n",
        "        image = image.transpose([2,0,1])    # (H,W,B) to (B,H,W)\n",
        "        \n",
        "        image_tensor = torch.from_numpy(image).float()\n",
        "        label_tensor = torch.from_numpy(label).long()\n",
        "        \n",
        "        return image_tensor, label_tensor\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    # Rotation function\n",
        "    def _rotate(self, image, rotation):\n",
        "        if rotation == 0:\n",
        "            return image\n",
        "        elif rotation == 90:\n",
        "            image = image.swapaxes(0,1)\n",
        "            return np.flip(image, axis=0)\n",
        "        elif rotation == 180:\n",
        "            image = np.flip(image, axis=0)\n",
        "            return np.flip(image, axis=1)\n",
        "        elif rotation == 270:\n",
        "            image = image.swapaxes(0,1)\n",
        "            return np.flip(image, axis=1)\n",
        "        else:\n",
        "            raise RuntimeError\n",
        "\n",
        "    # Flip function\n",
        "    def _flip(self, image, direction):\n",
        "        if direction == 'H':\n",
        "            return np.flip(image, axis=1)\n",
        "        elif direction == 'V':\n",
        "            return np.flip(image, axis=0)\n",
        "        elif direction == 'N':\n",
        "            return image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avGcOqStSsfL",
        "colab_type": "text"
      },
      "source": [
        "データセットからいくつかのパッチをサンプリングして、拡張性を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tv6T5cYSsfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from matplotlib.gridspec import GridSpec\n",
        "grid = GridSpec(nrows=2, ncols=10)\n",
        "\n",
        "\n",
        "mean = np.array([75, 75, 75])\n",
        "std = np.array([50, 50, 50])\n",
        "\n",
        "mean = mean[:, np.newaxis, np.newaxis]\n",
        "std = std[:,np.newaxis, np.newaxis]\n",
        "\n",
        "dataset = Buildings('./building_vmnih/train/patches/sat.npy', './building_vmnih/train/patches/map.npy', augmentation=True)\n",
        "\n",
        "fig = plt.figure(figsize=(20,4))\n",
        "for i in range(10):\n",
        "    image_tensor, label_tensor = dataset[3]\n",
        "    image_patch = image_tensor.detach().numpy() * std + mean\n",
        "    label_patch = label_tensor.detach().numpy()\n",
        "    \n",
        "    image_patch = image_patch.transpose([1,2,0])\n",
        "    image_patch = image_patch.clip(0,255).astype(np.uint8)\n",
        "\n",
        "    ax = fig.add_subplot(grid[0,i])\n",
        "    ax.imshow(image_patch, interpolation='none')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "    ax = fig.add_subplot(grid[1,i])\n",
        "    ax.imshow(label_patch, interpolation='none')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7fEswydSsfO",
        "colab_type": "text"
      },
      "source": [
        "**より多くのエポックを持つ大規模データを使用して、訓練されたモデルの結果を表示する**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIXO-qmeVZFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('fig/bulding_detct.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y70yCbTsSsfP",
        "colab_type": "text"
      },
      "source": [
        "このような手法は、ラベル付きデータの量が限られている場合に特に効果的です。\n",
        "他の方法があります \n",
        "- 転移学習\n",
        "- データ融合\n",
        "- 拡張畳み込み\n"
      ]
    }
  ]
}