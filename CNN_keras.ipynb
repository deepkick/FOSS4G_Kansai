{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"},"colab":{"name":"CNN_keras.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"af0-nQLi5nee","colab_type":"text"},"source":["## Convolutional Neural Network (CNN)"]},{"cell_type":"markdown","metadata":{"id":"iCIGFuQ75nef","colab_type":"text"},"source":["What is convolution ?"]},{"cell_type":"code","metadata":{"id":"feGoyOI460L5","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dH3lNv697Ubk","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/content/drive/My Drive/FOSS4G_Kansai/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdLJ_3R3-Xr7","colab_type":"code","colab":{}},"source":["!pwd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGtrFLaY7h7p","colab_type":"code","colab":{}},"source":["from IPython.display import Image\n","Image('fig/cnn1.png')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0V5W1NoS5neh","colab_type":"text"},"source":["It is an example of an image with  32 $*$ 32 pixels (length and width) 3 spectral bands (3 channels), 5 $*$ 5 kernel_size size [1]"]},{"cell_type":"markdown","metadata":{"id":"OKtVs1By5nei","colab_type":"text"},"source":["The below figure shows,how exactly it works"]},{"cell_type":"code","metadata":{"id":"bwwfL8k09aFc","colab_type":"code","colab":{}},"source":["Image('fig/cnn2.png')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vJVrLPWW5nej","colab_type":"text"},"source":["Each filter is independantly convolved with image and end up with user defined number of features. In the following figure has 6 features representation derived  from 6 filters."]},{"cell_type":"code","metadata":{"id":"8Oe6b_ce_aar","colab_type":"code","colab":{}},"source":["Image('fig/cnn3.png')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pitw9qH-5nel","colab_type":"text"},"source":["Where, CNN is collection of defined number of convolutional layers (blocks), convolutional (featues) result from one layer will be passed to the next layer as input as shown figure below; "]},{"cell_type":"code","metadata":{"id":"50f24N1Q_hGM","colab_type":"code","colab":{}},"source":["Image('fig/cnn4.png')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"72yl2LF25nem","colab_type":"text"},"source":["**Let us go to more details by making our own simple CNN using Keras**"]},{"cell_type":"code","metadata":{"id":"2hNAHiFx5nen","colab_type":"code","colab":{}},"source":["import numpy as np\n","import keras\n","x_train,y_train = np.load('dataset/isprs_vaihingen/train/patches/image.npy'),np.load('dataset/isprs_vaihingen/train/patches/label.npy')\n","x_test,y_test = np.load('dataset/isprs_vaihingen/val/patches/image.npy'),np.load('dataset/isprs_vaihingen/val/patches/label.npy')\n","channel = x_train.shape[-1]\n","num_classes = 5\n","img_rows, img_cols = 256, 256\n","input_shape = (img_rows, img_cols, channel)\n","y_tra = keras.utils.to_categorical(y_train, num_classes)\n","y_tes = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvyrhyFP5nep","colab_type":"code","colab":{}},"source":["from keras.models import Sequential, Model\n","from keras.layers import Dense,Input,Activation,Conv2D, MaxPooling2D,UpSampling2D, Dropout,Conv2DTranspose, concatenate, Flatten,BatchNormalization"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cYhcc3xq5ner","colab_type":"text"},"source":["Check the **filters**, **kernel size**, **padding**,**strides**, **pooling** and number of **parameters** generated"]},{"cell_type":"code","metadata":{"id":"aZG4B-cU5ner","colab_type":"code","colab":{}},"source":["input_shape = (256, 256, 3)\n","model = Sequential()\n","model.add(Conv2D(filters = 10, kernel_size = (5,5), strides =1,padding = 'valid', \n","                 input_shape=input_shape, activation='relu'))\n","\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WNTZtV185net","colab_type":"text"},"source":["**What is padding**  ?"]},{"cell_type":"markdown","metadata":{"id":"-QoEs4od5neu","colab_type":"text"},"source":["**Padding** is to add extra pixels to  outside the image to retain the original shape of the image after convolution [2]. "]},{"cell_type":"code","metadata":{"id":"KzLC73QHOfaS","colab_type":"code","colab":{}},"source":["with open('./fig/no_padding_no_strides.gif','rb') as f:\n","    display(Image(data=f.read(),width=400,height=500, format='png'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8X02j6FEO4u5","colab_type":"code","colab":{}},"source":["with open('./fig/arbitrary_padding_no_strides.gif','rb') as f:\n","    display(Image(data=f.read(), format='png'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_V9SmfwC5new","colab_type":"code","colab":{}},"source":["model = Sequential()\n","model.add(Conv2D(filters = 10, kernel_size = (5,5), strides = 1, padding = 'same', \n","                 input_shape=input_shape, activation='relu'))\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"52Ngg4qB5nex","colab_type":"text"},"source":["**Strides** is the unit of pixels which used to convolve  the kernel."]},{"cell_type":"code","metadata":{"id":"OSEtHsT4UjLz","colab_type":"code","colab":{}},"source":["with open('./fig/no_padding_strides.gif','rb') as f:\n","    display(Image(data=f.read(), width=400,height=500, format='png'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eyx3tnAzUzIY","colab_type":"code","colab":{}},"source":["with open('./fig/padding_strides.gif','rb') as f:\n","    display(Image(data=f.read(), width=400,height=500, format='png'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NtamTDCs5nez","colab_type":"code","colab":{}},"source":["model = Sequential()\n","model.add(Conv2D(filters = 10, kernel_size = (5,5), strides = 2, padding = 'same', \n","                 input_shape=input_shape, activation='relu'))\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lbw8g7LU5ne1","colab_type":"text"},"source":["**Pooling layer** downsamples the volume spatially, independently in each of the input feature. This function use to reduce the spatial size and hence reduce the number of paramters and computation. Eg: maxpool, averagepool"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"F2YOvcKSV3aN","colab":{}},"source":["Image('fig/pooling.png', width=800, height=350)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z24f0p-75ne2","colab_type":"code","colab":{}},"source":["model = Sequential()\n","model.add(Conv2D(filters = 10, kernel_size = (5,5), strides = 1, padding = 'same', \n","                 input_shape=input_shape, activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ytsXlRf15ne3","colab_type":"text"},"source":["**Building Encoder-decoder CNN network in Keras**"]},{"cell_type":"markdown","metadata":{"id":"RQng6wqe5ne4","colab_type":"text"},"source":["This is CNN network consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer.Several well-known Encoder-decoder is available such as Segnet, U-net, Deconv-net etc,."]},{"cell_type":"markdown","metadata":{"id":"siC8jXoJ5ne5","colab_type":"text"},"source":["Let us define our own simple Encoder-decoder network. "]},{"cell_type":"markdown","metadata":{"id":"yfNf9od95ne5","colab_type":"text"},"source":["First of all define the encoder part"]},{"cell_type":"code","metadata":{"id":"8jDa2S505ne6","colab_type":"code","colab":{}},"source":["inputs = Input((input_shape))\n","conv1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n","pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool1)\n","pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ItryhT7Q5ne7","colab_type":"code","colab":{}},"source":["keras.backend.int_shape(pool2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4W-TjZxY5ne9","colab_type":"text"},"source":["Define the decoder part"]},{"cell_type":"code","metadata":{"id":"i-j2f45X5ne-","colab_type":"code","colab":{}},"source":["conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool2)\n","up1 = UpSampling2D(size=(2, 2),interpolation='nearest')(conv3)\n","conv4 = Conv2D(16, (3, 3), activation='relu', padding='same')(up1)\n","up2 = UpSampling2D(size=(2, 2),interpolation='nearest')(conv4)\n","conv5 = Conv2D(num_classes, (1, 1), activation='softmax')(up2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgyeD_MK5nfA","colab_type":"code","colab":{}},"source":["keras.backend.int_shape(conv5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ihr7qhM75nfB","colab_type":"code","colab":{}},"source":["model = Model(inputs=[inputs], outputs=[conv5])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MOe0a3fp5nfD","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D-HXhfNy5nfH","colab_type":"code","colab":{}},"source":["BATCH_SIZE= 32\n","EPOCHS = 5\n","#SGD = keras.optimizers.SGD(lr=0.01)\n","SGD = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n","catergorical = keras.losses.categorical_crossentropy\n","accuracy = ['accuracy']\n","model.compile(loss = catergorical, optimizer = SGD,\n","              metrics = accuracy)\n","\n","history1 = model.fit(x_train, y_tra,\n","                    batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data = (x_test, y_tes))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J0H2MVJl5nfK","colab_type":"text"},"source":["Load data for prediction"]},{"cell_type":"code","metadata":{"id":"NEk3haPw5nfL","colab_type":"code","colab":{}},"source":["x_pred,y_pred = np.load('./dataset/isprs_vaihingen/test/patches/image.npy'),np.load('./dataset/isprs_vaihingen/test/patches/label.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUpIsWmm5nfP","colab_type":"code","colab":{}},"source":["Predict_prob = model.predict(x_pred)\n","Predict_prob.shape\n","Predict_class = np.argmax(Predict_prob,axis=-1)\n","Predict_class.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qG3uf7y5nfR","colab_type":"code","colab":{}},"source":["y_pred.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NndwMPjx5nfS","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","import matplotlib.pyplot as  plt\n","fig = plt.figure()\n","ax = fig.add_subplot(121)\n","ax.imshow(Predict_class[4], interpolation='none')\n","ax.set_xticks([])\n","ax.set_yticks([])\n","ax.set_title('Predict')\n","fig.show()\n","\n","ax = fig.add_subplot(122)\n","ax.imshow(y_pred[4], interpolation='none')\n","ax.set_xticks([])\n","ax.set_yticks([])\n","ax.set_title('Label')\n","\n","fig.suptitle('Scene: top_mosaic_09cm_area1')\n","fig.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FK5A66AH5nfY","colab_type":"text"},"source":["**U-net; a deep Convolutional Networks**"]},{"cell_type":"markdown","metadata":{"id":"L16fGHLI5nfZ","colab_type":"text"},"source":["U-net is an end-to-end network with U-shape. U-net consists of a contracting path (left-side) and an expansive path (right side). U-net has special architecture which concatenate lost features in the downsampling process with the appropriate features in the upsampling process. This particular aspect makes U-net as an elegant deep learning network[3]."]},{"cell_type":"code","metadata":{"id":"Tnvv-PhaYL3r","colab_type":"code","colab":{}},"source":["Image('fig/Unet.png', width=600, height = 400)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_NDf9mxX5nfa","colab_type":"code","colab":{}},"source":["inputs = Input((input_shape))\n","# Encoder\n","conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n","conv1 = BatchNormalization()(conv1)\n","conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n","pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n","conv2 = BatchNormalization()(conv2)\n","conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n","pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n","conv3 = BatchNormalization()(conv3)\n","conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n","pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n","conv4 = BatchNormalization()(conv4)\n","conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n","pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","# Decoder\n","conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n","up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n","conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n","conv6 = BatchNormalization()(conv6)\n","conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n","up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n","conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n","conv7 = BatchNormalization()(conv7)\n","conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n","up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n","conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n","conv8 = BatchNormalization()(conv8)\n","conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n","up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n","conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n","conv9 = BatchNormalization()(conv9)\n","conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n","conv10 = Conv2D(num_classes, (1, 1), activation='softmax')(conv9)\n","model = Model(inputs=[inputs], outputs=[conv10])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rqrbwUnd5nfb","colab_type":"code","colab":{}},"source":["BATCH_SIZE= 24\n","EPOCHS = 2\n","#SGD = keras.optimizers.SGD(lr=0.01)\n","SGD = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n","catergorical = keras.losses.categorical_crossentropy\n","accuracy = ['accuracy']\n","model.compile(loss = catergorical, optimizer = SGD,\n","              metrics = accuracy)\n","\n","history1 = model.fit(x_train, y_tra,\n","                    batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data = (x_test, y_tes))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5D4i0Ygf5nfd","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","from keras.models import model_from_json\n","model_json = model.to_json()\n","with open(\"./learned_weights/demo_model.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model.save_weights(\"./learned_weights/demo_model.h5\")\n","print(\"Saved model to disk\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BUe9XtbO5nfe","colab_type":"code","colab":{}},"source":["Predict_prob = model.predict(x_pred)\n","Predict_prob.shape\n","Predict_class = np.argmax(Predict_prob,axis=-1)\n","Predict_class.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"TDZs4-N45nfg","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","fig = plt.figure()\n","ax = fig.add_subplot(121)\n","ax.imshow(Predict_class[1], interpolation='none')\n","ax.set_xticks([])\n","ax.set_yticks([])\n","ax.set_title('Predict')\n","fig.show()\n","\n","ax = fig.add_subplot(122)\n","ax.imshow(y_pred[1], interpolation='none')\n","ax.set_xticks([])\n","ax.set_yticks([])\n","ax.set_title('Label')\n","\n","fig.suptitle('Scene: top_mosaic_09cm_area1')\n","fig.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xot4JVES5nfi","colab_type":"code","colab":{}},"source":["#import h5py\n","json_file = open('./learned_weights/model.json', 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","loaded_model = model_from_json(loaded_model_json)\n","# load weights into new model\n","loaded_model.load_weights(\"./learned_weights/model.h5\")\n","print(\"Loaded model from disk\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQFvUXFx5nfj","colab_type":"code","colab":{}},"source":["Predict_prob = loaded_model.predict(x_pred)\n","Predict_prob.shape\n","Predict_class = np.argmax(Predict_prob,axis=-1)\n","Predict_class.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XJdXXTM65nfl","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","fig = plt.figure()\n","ax = fig.add_subplot(121)\n","ax.imshow(Predict_class[1], interpolation='none')\n","ax.set_xticks([])\n","ax.set_yticks([])\n","ax.set_title('Predict')\n","fig.show()\n","\n","ax = fig.add_subplot(122)\n","ax.imshow(y_pred[1], interpolation='none')\n","ax.set_xticks([])\n","ax.set_yticks([])\n","ax.set_title('Label')\n","\n","fig.suptitle('Scene: top_mosaic_09cm_area1')\n","fig.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1IdbCTqS5nfn","colab_type":"text"},"source":["**Reference**"]},{"cell_type":"markdown","metadata":{"id":"s6D22bIE5nfn","colab_type":"text"},"source":["1. Harsh Pokharna, The best explanation of Convolutional Neural Networks on the Internet\n","2. Vincent Dumoulin, Francesco Visin - A guide to convolution arithmetic for deep learning (BibTeX)\n","3. Olaf Ronneberger, Philipp Fischer, Thomas Brox, U-Net: Convolutional Networks for Biomedical Image Segmentation\n"]}]}